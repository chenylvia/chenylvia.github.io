---
layout: post
title:  "理解大模型中的温度参数"
author: "chenylvia"
comments: true
tags: 其他
excerpt_separator: <!--more-->
sticky: true
hidden: true


---

在使用大模型或调用大模型接口时，通常有一个温度参数需要配置，刚使用时可能并不清楚如何设置这一参数值，以及该值对大模型输出结果的影响。本文讲解温度参数的基本原理和常规使用，来帮助大家理解温度参数。<!--more-->

## 一、温度参数是什么

温度参数是大模型使用中的一个常见配置。例如xxx模块，有个配置temperature，它就是温度参数。平台对它的解释是：

> 要使用的采样温度（temperature），介于 0 和 2 之间。较高的值（如 0.8）会使输出更随机，而较低的值（如 0.2）则会使其更加专注和确定。我们通常建议只修改此参数或 top_p 一个参数而不是两个同时修改，默认为1.0, 0表示贪婪采样。

![image-20250630190355774]()

使用xxxSDk时，也会设置温度值：

![image-20250630190815645]()

在大模型中，温度参数（temperature）用来控制输出结果的确定性。该参数值是一个大于0的数值，通常取值范围在0到2之间。当值较低时，对应输出结果确定性较高。反之输出结果确定性较低，随机性较高。

## 二、温度参数对大模型输出的影响

在理解温度参数的基本原理之前，先理解原始分数和Softmax函数。

* 原始分数

  当大模型准备生成一个词时，它会为词汇表中的每一个可能的词计算一个原始分数，也可称为置信度。原始分数表示模型生成每个词的可能性，它们可以是任何实数（正数、负数或零）。原始分数值越大，模型认为这个词越可能出现。

* Softmax函数：

  Softmax函数又称为归一化指数函数，用于将原始分数转换为可以理解的概率分布（所有词的概率之和为1），该函数用数学表达式可表示为：
  $$
  P_i = e^{z_i} / \sum_j e^{z_j}
  $$
  其中$P_i$表示概率，$z_i$表示模型输出的原始分数。

假设模型在生成下一个词时，原始分数的概率分布通过Softmax函数计算。通过温度参数来调整原始分数$z_i$的概率分布，数学表达式如下：
$$
P_i(T) = e^{z_i / T} / \sum_j e^{z_j / T}
$$
从上述数学表达式可看出，当温度值T小于1时，由于原始分数除以一个小于1的数，它的值会被放大，这意味着原始分数之间的差异会增大。经过Softmax函数处理后，高概率词的概率会进一步上升，低概率的词的概率会进一步下降。结果使得概率分布变得尖锐，模型会更强烈地选择偏向于原始分数最高的词，这使得输出结果更加确定。T等于1时，原始概率分布保持不变，

温度值T等于1，保持原始分数的概率分布不变，相当于直接使用模型输出的原始分数进行采样，输出较为平衡。

当温度值T大于1，会缩小原始分数之间的差异。经过Softmax函数后后，高概率词生成的概率会下降，低概率词生成的概率会上升。结果是概率分布变更平台，模型在生成下一个词时，会倾向于从更多不同的词中随机选择，增加了输出结果的随机性和多样性，但可能降低逻辑性。

## 三、总结

在配置温度参数的过程中，如果配置较高的数值，会使大模型输出结果更加随机，配置较低的数值则输出结果更加确定。不同的温度值范围有不同的应用场景，例如在低温值（0-0.5）情况下，模型输出的确定性较高，常用于代码生成等对输出一致性要求高的场景。高温值（ > 1）则常用于对创造性要求高的场景，例如文学创作、头脑风暴的场景中。在使用过程中因结合实际需求场景来设置温度值，同时根据模型输出的结果来进行调整，达到良好的输出效果。

| 温度值范围      | 输出效果                                     | 应用场景           |
| --------------- | -------------------------------------------- | ------------------ |
| 低温（0 - 0.5） | 输出确定性高                                 | 代码生成、法律文本 |
| 中温（0.5 - 1） | 输出确定性和随机性较为平衡                   | 对话系统、常规文本 |
| 高温（ > 1）    | 输出随机性高，更具创造力，但可能导致逻辑混乱 | 文学创作、头脑风暴 |